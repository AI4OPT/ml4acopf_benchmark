{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "jmKAsGzoMhmK",
        "outputId": "6d651824-d044-4bc6-9251-22c2b90a3d9e"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'vnn' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/Users/haoruo/Documents/GitHub/ml4acopf_benchmark/venv/vnn/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import onnx2pytorch\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import torch\n",
        "\n",
        "x = torch.load('input_instance_0.pt')\n",
        "onnx_model = onnx.load('onnx/300_ieee_ml4acopf.onnx')\n",
        "pytorch_model = onnx2pytorch.ConvertModel(onnx_model)\n",
        "pytorch_model.eval()\n",
        "\n",
        "sess = ort.InferenceSession(onnx_model.SerializeToString())\n",
        "output_onnx = sess.run(None, {sess.get_inputs()[0].name: x.numpy()})[0]\n",
        "\n",
        "output_pytorch = pytorch_model(x)\n",
        "\n",
        "print((torch.tensor(output_onnx) - output_pytorch).abs().max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
