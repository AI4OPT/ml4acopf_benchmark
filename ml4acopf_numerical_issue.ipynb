{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "jmKAsGzoMhmK",
        "outputId": "6d651824-d044-4bc6-9251-22c2b90a3d9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/haoruo/Documents/GitHub/ml4acopf_benchmark/venv/vnn/lib/python3.9/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
            "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Automatic inference of operator: cos\n",
            "Automatic inference of operator: sin\n",
            "Automatic inference of operator: neg\n",
            "tensor(0.0020, grad_fn=<MaxBackward1>)\n"
          ]
        }
      ],
      "source": [
        "import onnx2pytorch\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import torch\n",
        "\n",
        "x = torch.load('input_instance_0.pt')\n",
        "onnx_model = onnx.load('onnx/300_ieee_ml4acopf.onnx')\n",
        "pytorch_model = onnx2pytorch.ConvertModel(onnx_model)\n",
        "pytorch_model.eval()\n",
        "\n",
        "sess = ort.InferenceSession(onnx_model.SerializeToString())\n",
        "output_onnx = sess.run(None, {sess.get_inputs()[0].name: x.numpy()})[0]\n",
        "\n",
        "output_pytorch = pytorch_model(x)\n",
        "\n",
        "print((torch.tensor(output_onnx) - output_pytorch).abs().max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Automatic inference of operator: cos\n",
            "Automatic inference of operator: sin\n",
            "Automatic inference of operator: neg\n"
          ]
        },
        {
          "ename": "NotImplemented",
          "evalue": "[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for Cos(7) node with name '/Cos_0/Cos'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplemented\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m pytorch_model \u001b[39m=\u001b[39m onnx2pytorch\u001b[39m.\u001b[39mConvertModel(onnx_model)\n\u001b[1;32m      9\u001b[0m pytorch_model\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> 11\u001b[0m sess \u001b[39m=\u001b[39m ort\u001b[39m.\u001b[39;49mInferenceSession(onnx_model\u001b[39m.\u001b[39;49mSerializeToString())\n\u001b[1;32m     12\u001b[0m output_onnx \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39mrun(\u001b[39mNone\u001b[39;00m, {sess\u001b[39m.\u001b[39mget_inputs()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mname: x\u001b[39m.\u001b[39mnumpy()})[\u001b[39m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m output_pytorch \u001b[39m=\u001b[39m pytorch_model(x)\n",
            "File \u001b[0;32m~/Documents/GitHub/ml4acopf_benchmark/venv/vnn/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:383\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m disabled_optimizers \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mdisabled_optimizers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdisabled_optimizers\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_inference_session(providers, provider_options, disabled_optimizers)\n\u001b[1;32m    384\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    385\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_fallback:\n",
            "File \u001b[0;32m~/Documents/GitHub/ml4acopf_benchmark/venv/vnn/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:435\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    432\u001b[0m     disabled_optimizers \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(disabled_optimizers)\n\u001b[1;32m    434\u001b[0m \u001b[39m# initialize the C++ InferenceSession\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m sess\u001b[39m.\u001b[39;49minitialize_session(providers, provider_options, disabled_optimizers)\n\u001b[1;32m    437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess \u001b[39m=\u001b[39m sess\n\u001b[1;32m    438\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess_options \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess\u001b[39m.\u001b[39msession_options\n",
            "\u001b[0;31mNotImplemented\u001b[0m: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for Cos(7) node with name '/Cos_0/Cos'"
          ]
        }
      ],
      "source": [
        "import onnx2pytorch\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import torch\n",
        "\n",
        "x = torch.load('input_instance_0.pt')\n",
        "onnx_model = onnx.load('onnx/300_ieee_ml4acopf.onnx.64bit')\n",
        "pytorch_model = onnx2pytorch.ConvertModel(onnx_model)\n",
        "pytorch_model.eval()\n",
        "\n",
        "sess = ort.InferenceSession(onnx_model.SerializeToString())\n",
        "output_onnx = sess.run(None, {sess.get_inputs()[0].name: x.numpy()})[0]\n",
        "\n",
        "output_pytorch = pytorch_model(x)\n",
        "\n",
        "print((torch.tensor(output_onnx) - output_pytorch).abs().max())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
